{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\bm{26}$ $\\enspace$ **网络中的网络 NiN**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\bm{26.1}$ $\\enspace$ **NiN 块**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NiN](image/NiN.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "def nin_block(in_channels, out_channels, kernel_size, strides, paddings):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, strides, paddings),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "        nn.ReLU()\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\bm{26.2}$ $\\enspace$ **NiN 模型**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NiN 和 AlexNet 之间的一个显著区别是 NiN 完全取消了全连接层。相反，NiN 使用一个 NiN 块，其输出通道数等于标签类别的数量。最后放一个全局平均汇聚层 (global average pooling layer)，生成一个对数几率 (logits)。NiN 设计的一个优点是，它显著减少了模型所需参数的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nin_block(1, 96, kernel_size=11, strides=4, paddings=0),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nin_block(96, 256, kernel_size=5, strides=1, paddings=2),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nin_block(256, 384, kernel_size=3, strides=1, paddings=1),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Dropout(0.5),\n",
    "    # 标签类别数是10\n",
    "    nin_block(384, 10, kernel_size=3, strides=1, paddings=1),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    # 将四维的输出转成二维的输出，其形状变为10\n",
    "    nn.Flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(size=(1, 1, 224, 224))\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, \"output shape:\\t\", X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\bm{26.3}$ $\\enspace$ **训练模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.1, 10, 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "719f98299ccca36a884f9d141671719e20aaacc8082e234f139e455a4a5b836e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
